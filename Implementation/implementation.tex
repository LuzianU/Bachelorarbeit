\chapter{Implementation}
\label{ch:implementation}

Die Implementation der verschiedenen Deep-Learning Bilderkennungsmethoden erfolgte durch die Verwendung des Ultralytics YOLO \cite{Jocher_Ultralytics_YOLO_2023} Frameworks und der Eigenimplementation der U-Net \cite{ronneberger2015unetconvolutionalnetworksbiomedical} Architektur. Alle folgenden Modelle wurden auf einer NVIDIA GeForce RTX 3090 mit 24252 MiB Grafikkartenspeicher trainiert.

\section{Ultralytics YOLO}
Für die Extraktion von Diagrammen aus Texten, Schwierigkeitsklassifizierung von Liniendiagrammen und Instanzsegmentation der Wertelinien wurde das Ultralytics YOLO Framework verwendet. Es basiert auf der YOLO (You Only Look Once) Architektur, welche erstmal 2015 \cite{redmon2016lookonceunifiedrealtime} veröffentlicht wurde, und seit dem zehn Versionsiterationen durchlief. Unterstützt werden verschiedene Bild- und Videoerkennungsaufgaben, wie die Erkennung (detection), Segmentierung (segmentation), Posenschätzung (pose detection), Verfolgung (tracking) und Klassifizierung (classification). Das Ultralytics YOLO Framework ist anfängerfreundlich, die Verwendung erfolgt einfach, verfügt man bereits über einen annotierten Datensatz, kann mit lediglich einem Konsolenbefehl der Trainingsprozess des eigenen Modells gestartet werden. Ebenfalls verfügt es über der automatischen Datenagumentation während des Trainingsvorgangs und der Evaluation verschiedener Metriken des trainierenden und trainierten Modells.
\\
Ultralytics stellt zu dem Großteil der zehn YOLO Architekturen bereits vortrainierte herunterladbare Modelle bereit. Für das Vortrainieren der Objekterkennung, Klassifizierung und Instanzsegmentation wurde der COCO \cite{lin2015microsoftcococommonobjects} Datensatz verwendet, welcher aus über 200.000 Bildern besteht und  eingeteilt wurde auf 80 Objektklassen.

Diese werden außerdem in verschiedene Modellgrößen angeboten, sodass die Möglichkeit besteht zwischen Invarianzgeschwindigkeit, benötigte Gleitkommaoperationsleistungsfähigkeiten und verwendbaren Grafikkartenspeicher abwegegen zu können.
\\
Es wurden verschiedene YOLO Modelle verwendet, an denen jedoch keine Architekturänderungen vorgenommen wurden.
Sofern im Weiteren nicht explizit angegeben, wurden die Grundeinstellungen des Ultralytics YOLO Frameworks benutzt. Die genaue Anzahl der Trainingsepochen variierte zwischen den einzelnen Trainingsvorgängen, da bei allen die Geduldseinstellung (patience) von 100 Epochen verwendet wurde. Um die Überanpassung (over-fitting) an den Trainingsdatensatz zu vermeiden, wird mit diesem Geduldsparameter das Training vorzeitig abgebrochen, solange in den letzten beliebigen Epochen das trainierende Modell keine Verbesserungen der Validationsmetriken aufweisen konnte.

\subsection{Objekterkennung zur Extraktion von Diagrammen aus Texten}

Für die Erkennung aller Diagrammen in den Vollseitscans wurde das YOLOv9e Modell verwendet.
\\
Zuerst wurde es auf den in \ref{ch:chartbank} beschreibenen, selbst erstellten DocBank Datensatz vortrainiert (pre-trained) und danach auf den Datensatz aus \ref{ch:scanbank}, der historischen Wirtschaftsscans, feintrainiert (fine-tuned).
\\
Es wurde die Bildgröße von 1024x1024 Pixel verwendet und eine Batchgröße von 7 gewählt, da für eine höhere Batchgröße die verwendete Grafikkarte über ungenügend viel Speicher verfügte. Die von den Grundeinstellungen geänderten Parametern der Datenaugmentierung, mitsamt ihrer jeweiligen Wahrscheinlichkeiten, bestanden aus:

\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item Farbmanipulation im HSV-Farbraum: Hue (1.0), Sättigung (1.0) und Helligkeit (0.5)
    \item BGR-Kanaländerung (0.5)
    \item Skalierung (1.0)
    \item Vertikales Spiegeln (0.1)
    \item Überlagern von Bildern (Mixup, 1.0)
\end{itemize}

Gewählt wurden diese Augmentierungstechniken mit dem Ziel die universelle Erkennungsfähigkeiten des trainierted Modells zu stärken. Farbmanipulationen helfen dem Modell zuversichtlichere Vorhersagen auf einer breiten Spanne unterschiedlicher Papierhintergründe zu treffen, beziehungsweise Diagramme mit willkürlichen Farben besser zu erkennen.


\subsection{Klassifizierung zur Schwierigkeitsbestimmung von Liniendiagrammen}
abc
\subsection{Instanzsegmentation von Wertelinien in Liniendiagrammen}
abc


\section{U-Net}
abc

\section{Numerische Auswertung von Liniendiagrammen in Tabellenform}
abc



Für das Kapitel "Implementation" in Ihrer Bachelorarbeit über YOLO und U-Net sollten Sie sich auf die praktischen Aspekte der Umsetzung dieser Modelle konzentrieren. Hier sind einige Punkte, die Sie berücksichtigen sollten:

Technische Details der Implementierung:

Verwendete Programmiersprache und Frameworks (z.B. Python, PyTorch, TensorFlow)
Benötigte Hardware (GPUs, etc.)
Verwendete Bibliotheken und deren Versionen


Architektur-Anpassungen:

Spezifische Änderungen, die Sie an den Standard-YOLO- und U-Net-Architekturen vorgenommen haben
Begründung für diese Anpassungen


Datenaufbereitung:

Beschreibung der Datenvorverarbeitung
Augmentierungstechniken, falls verwendet


Hyperparameter:

Gewählte Hyperparameter (Lernrate, Batchgröße, etc.)
Begründung für die Wahl dieser Parameter


Training:

Kurze Beschreibung des Trainingsprozesses (Anzahl der Epochen, Optimierungsmethode)
Verwendete Loss-Funktionen


Inferenz:

Beschreibung, wie die trainierten Modelle für Vorhersagen eingesetzt werden


Herausforderungen und Lösungen:

Technische Schwierigkeiten, die während der Implementierung auftraten
Wie Sie diese Herausforderungen bewältigt haben



Die detaillierte Funktionsweise von YOLO und U-Net gehört eher in den theoretischen Teil oder in das Grundlagenkapitel Ihrer Arbeit. Die spezifischen Experimente, Ergebnisse und deren Auswertung sollten in einem separaten Kapitel "Experimente und Ergebnisse" behandelt werden.
Das Implementierungskapitel konzentriert sich auf die technischen Aspekte und praktischen Schritte, die Sie unternommen haben, um die Modelle für Ihr spezifisches Problem umzusetzen. Es bildet die Brücke zwischen der Theorie und den konkreten Experimenten.