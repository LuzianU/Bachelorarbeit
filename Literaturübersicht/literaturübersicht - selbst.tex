\chapter{Literaturübersicht}
\label{ch:literaturübersicht}

Im Bereich der Dokumenten-Analyse gibt es in der Litetur einige Methoden und Datensätze. Insbesondere die Erkennung in digitalen Dokumenten ist breit erforscht. Der bildbasierte TableBank \cite{li2019tablebank} Datensatz stellt eine große Anzahl Ganzseitbilder mit annotierten Tabellen bereit. Im Verglich zu historischen Scans besteht hier die Möglichkeit Annotaiton durch das Verarbeiten der LaTeX und Microsoft Word Quelldateien automatisch zu erstellen. Darauf aufbauend geht DocBank \cite{li2020docbank} einen Schritt weiter und stellt die Erkennungen ganzer Dokumentenlayouts zu Verfügung. Eigeordnet werden Die Dokumentenseiten hier in 12 verschieden Einheiten von Paragraphen, Formeln über Abbildungen und Tabellen. Für die Erkennung erforscht wurde hier nicht nur die Verwendung der Bilderseiten selbst, sondern auch die Mithilfe von NLP Methoden um so eine besodners detailierte Menge an Dokumentenelementen bereitzustellen.

Die automatische Transkription von Liniendiagrammen ist weit weniger erforscht als die von Tabellen, z.B. gibt es auf den ICDAR-Konferenzen (International Conference on Document Analysis and Recognition) keine Wettbewerbe (Challenges) mit annotierten Datensätzen, im Gegensatz zu Tabellen und vielen anderen Bereichen. Es gibt nur wenige Publikationen, die sich mit diesem Problem beschäftigen, wobei aktuelle Ansätze \cite{P2023LineEXDE, lee2023matgdmaterialsgraphdigitizer} Deep-Learning-Techniken verwenden, die mangels annotierter realer Daten überwiegend mit synthetischen Daten trainiert werden. In der Literatur wird die Erkennung von Liniendiagrammen meist in folgende Schritte unterteilt:

\begin{enumerate}[itemsep=0pt, topsep=0pt]
    \item Erkennen und Klassifizieren des Diagramms
    \item Erkennen der x- und y-Achse des Liniendiagramms
    \item Erkennen der Linien
    \item Erkennen der Beschriftungen
    \item Extraktion der Datenpunkte auf den Linien
    \item Zuordnung der Datenpunkte zu den semantischen x- und y-Werten
    \item Darstellung des Ergebnisses als Tabelle.
\end{enumerate}

Während einfache Linien gut erkannt werden, wird bei überlappenden Linien oft angenommen, dass diese farbig gezeichnet werden, um sie zu unterscheiden. Dies gilt jedoch nicht für historische Liniendiagramme, die in der Regel durch verschiedene gestrichelte Linien unterschieden werden, was automatisch schwer zu erkennen ist. Dafür eignen sich semiautomatische Ansätze wie z.B. in \cite{inproceedings} beschrieben. Hierbei werden die automatischen Schritte von den Anwendern sofort manuell überprüft und korrigiert, was bei einer Massentranskription nicht praktikabel, aber bei einer begrenzten Anzahl von Diagrammen realistisch ist, zumal eine Qualitätskontrolle für die GT-Erstellung ohnehin notwendig ist.
\\
Erforschte Herangehensweisen \cite{9423395} zur Linienerkennung und Datenextraktion bestehen unter anderem aus der Erkennung von Schlüsselpunkten (key point detection) der jeweiligen Wertelinien, welche hier durch Steigungsänderungen (pivot points) festgelegt werden. Nach deren Erkennung durch ein neurales Netzwerk werden diese mit Hilfe einer zusätzlichen Faltungsschicht (convolution layer) zu einzelnen Linieninstanzen gruppiert. Andere Linieninstanzgruppierungsalgorithmen \cite{parsingimages} bestehen in der Optimierung einer Kostenfunktion mithilfe der linearen Programmierung über ein Minimum-Kosten-Fluss-Problem (minimum-cost-flow problem). Im Vergleich zu handgeschriebenen, historischen Liniendiagrammen allerdings, bestehen die Datensätze exklusiv aus computergenerierten Textbeschriftungen, sodass die optische Schriftzeichenerkennung (optical character recognition) erfolgreicher durchgeführt werden kann. Die Zuordnung der Datenpunkte zu den semantischen x- und y-Werten erfolgt dadurch fehlerfreier, was wie bei allen Zwischenschritten die Effizienz des Endergebnisses direkt beeinflusst.
\\
Zur Evaluation werden die Linien als kontinuierliches Ähnlichkeitsproblem (continuous similarity problem) behandelt. Die Punktsequenz der Vorhersage des Modells und eine definierte Grundwahrheitsmenge werden verglichen, sodass Präzision (precision), Erinnerung (recall) und F1-Wert (F1-Score) berechnet werden können.
