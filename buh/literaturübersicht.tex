\chapter{Literaturübersicht}
\label{ch:literaturübersicht}

Die automatische Transkription von Liniendiagrammen ist weit weniger erforscht als die von Tabellen, z.B. gibt es auf den ICDAR-Konferenzen (International Conference on Document Analysis and Recognition) keine Wettbewerbe (Challenges) mit annotierten Datensätzen, im Gegensatz zu Tabellen und vielen anderen Bereichen. Es gibt nur wenige Publikationen, die sich mit diesem Problem beschäftigen, wobei aktuelle Ansätze \cite{P2023LineEXDE, lee2023matgdmaterialsgraphdigitizer} Deep-Learning-Techniken verwenden, die mangels annotierter realer Daten überwiegend mit synthetischen Daten trainiert werden. In der Literatur wird die Erkennung von Liniendiagrammen meist in folgende Schritte unterteilt:

\begin{enumerate}[itemsep=0pt, topsep=0pt]
    \item Erkennen und Klassifizieren des Diagramms
    \item Erkennen der x- und y-Achse des Liniendiagramms
    \item Erkennen der Linien
    \item Erkennen der Beschriftungen
    \item Extraktion der Datenpunkte auf den Linien
    \item Zuordnung der Datenpunkte zu den semantischen x- und y-Werten
    \item Darstellung des Ergebnisses als Tabelle.
\end{enumerate}
% (1) Erkennen und Klassifizieren des Diagramms, (2) Erkennen der x- und y-Achse des Liniendiagramms, (3) Erkennen der Linien, (4) Erkennen der Beschriftungen, (5) Extraktion der Datenpunkte auf den Linien, (6) Zuordnung der Datenpunkte zu den semantischen x- und y-Werten, (7) Darstellung des Ergebnisses als Tabelle. 
Während einfache Linien gut erkannt werden, wird bei überlappenden Linien oft angenommen, dass diese farbig gezeichnet werden, um sie zu unterscheiden. Dies gilt jedoch nicht für historische Liniendiagramme, die in der Regel durch verschiedene gestrichelte Linien unterschieden werden, was automatisch schwer zu erkennen ist. Dafür eignen sich semiautomatische Ansätze wie z.B. in \cite{inproceedings} beschrieben. Hierbei werden die automatischen Schritte von den Anwendern sofort manuell überprüft und korrigiert, was bei einer Massentranskription nicht praktikabel, aber bei einer begrenzten Anzahl von Diagrammen realistisch ist, zumal eine Qualitätskontrolle für die GT-Erstellung ohnehin notwendig ist.
\\
Erforschte Herangehensweisen \cite{9423395} zur Linienerkennung und Datenextraktion bestehen unter anderem aus der Erkennung von Schlüsselpunkten (key point detection) der jeweiligen Wertelinien, welche hier durch Steigungsänderungen (pivot points) festgelegt werden. Nach deren Erkennung durch ein neurales Netzwerk werden diese mit Hilfe einer zusätzlichen Faltungsschicht (convolution layer) zu einzelnen Linieninstanzen gruppiert. Andere Linieninstanzgruppierungsalgorithmen \cite{parsingimages} bestehen in der Optimierung einer Kostenfunktion mithilfe der linearen Programmierung über ein Minimum-Kosten-Fluss-Problem (minimum-cost-flow problem). Im Vergleich zu handgeschriebenen, historischen Liniendiagrammen allerdings, bestehen die Datensätze exklusiv aus computergenerierten Textbeschriftungen, sodass die optische Schriftzeichenerkennung (optical character recognition) erfolgreicher durchgeführt werden kann. Die Zuordnung der Datenpunkte zu den semantischen x- und y-Werten erfolgt dadurch fehlerfreier, was wie bei allen Zwischenschritten die Effizienz des Endergebnisses direkt beeinflusst.
\\
Zur Evaluation werden die Linien als kontinuierliches Ähnlichkeitsproblem (continuous similarity problem) behandelt. Die Punktsequenz der Vorhersage des Modells und eine definierte Grundwahrheitsmenge werden verglichen, sodass Präzision (precision), Erinnerung (recall) und F1-Wert (F1-Score) berechnet werden können.
