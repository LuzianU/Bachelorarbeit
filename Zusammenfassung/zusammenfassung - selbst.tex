
In dieser Arbeit wurde sich mit der Entwicklung und Evaluation eines Systems zur Extraktion verschiedener Diagramme in Texten und Auswertung von Liniendiagrammen aus historischen Wirtschaftsmagazinen beschäftigt. Hierfür wurde eine Kombination unterschiedlicher Deep-Learning-Techniken und traditionellen Bildbearbeitungsmethoden implementiert.
\\
Die experimentellen Ergebnisse zeigen, dass die gewählten Modelle vielversprechend für die automatische Extraktion und Klassifikation diverser Diagrammarten sind. Die semantische Segmentation der Wertelinien von Liniendiagrammen erwies sich als robuster im Vergleich zur Instanzsegmentation mit Ultralytics YOLO, insbesondere bei der korrekten Erkennung aller vorliegenden Wertelinien. Die Vereinigung der Segmentierungsergebnisse mit optischer Schriftzeichenerkennung für die Achsenbestimmung ermöglichte die grafische Darstellung und numerische Auswertung in Tabellenform.
\\
Allerdings gibt es auch Limitationen, die in zukünftigen Arbeiten weiter ausgearbeitet werden können. Durch das Wegefallen der Linieninstanzerkennung durch semantische Segmentation wurde ein simpler Linientrennungsalgorithmus entwickelt, welcher bei komplexeren, insbesondere bei sich überlappenden Linien, von Diagrammen zu Fehlern führt. Hierfür könnten Kombinationen aus semantischer und Instanzsegmentation oder sogar ganz andere erforschte fortschrittlichere Liniennachzeichnungs- oder Gruppierungsalgorithmen zu verbessernde Ergebnisse führen. Zudem ist die vorgeschlagende Methode stark von der Qualität der optischen Schriftzeichenerkennung abhängig, weshalb hierfür verschiedene OCR-Bibliotheken oder spezialisiert trainierte OCR-Modelle evaluiert werden könnten.
\\
Insgesamt bietet die entwickelten Methoden eine solide Grundlage für die weitere Forschung im Bereich der automatisierten Diagrammerkennung und -auswertung. Zukünftige Arbeiten könnten sich ebenfalls auf die Generalisierbarkeit dieser auf anderen Diagrammarten konzentrieren.
